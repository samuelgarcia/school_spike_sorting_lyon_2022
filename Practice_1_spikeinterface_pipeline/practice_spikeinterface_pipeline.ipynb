{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpikeInterface Tutorial -  GDR School Lyon - October 2021\n",
    "\n",
    "\n",
    "In this practice, you will use SpikeInterface to analyze a 64-channel dataset from am \"ASSY-156-P1\" probe from Cambridge Neurotech. \n",
    "The dataset is kindly provided by [Samuel McKenzie's Lab](https://mckenzieneurolab.com/). \n",
    "\n",
    "The objective of this practice is for you to familiarize with SpikeInterface on a real-world example and to explore its capabilities and functionalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "* [0. Preparation](#preparation)\n",
    "* [1. Loading the data and probe information](#loading)\n",
    "* [2. Preprocessing](#preprocessing)\n",
    "* [3. Saving and loading SpikeInterface objects](#save-load)\n",
    "* [4. Spike sorting](#spike-sorting)\n",
    "* [5. Extracting waveforms](#waveforms)\n",
    "* [6. Postprocessing](#postprocessing)\n",
    "* [7. Viewers](#viewers)\n",
    "* [8. Validation and curation](#curation)\n",
    "* [9. Spike sorting comparison](#comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Preparation <a class=\"anchor\" id=\"preparation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the ephys data\n",
    "\n",
    "First, we need to download the recording (you should have this already). Feel free to use your own recordings as well later on. \n",
    "\n",
    "The dataset is called `cambridge_data.dat` and can be found on this [drive link](https://drive.google.com/drive/folders/1eWPuOd8q4MjpVpwazkWygQJDzJnToN3i) (`practice_2_real_dataset` folder). Move the dataset in the current folder.\n",
    "The recording was performed with the \"ASSY-156-P1\" probe with 4 shanks of 16 channels (in total 64 channels).\n",
    "\n",
    "\n",
    "### Import the modules\n",
    "\n",
    "Let's now import the `spikeinterface` modules that we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface as si\n",
    "import spikeinterface.extractors as se \n",
    "import spikeinterface.toolkit as st\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.comparison as sc\n",
    "import spikeinterface.widgets as sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading recording and probe information <a class=\"anchor\" id=\"loading\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path\n",
    "recording_file = 'cambridge_data.dat'\n",
    "\n",
    "# parameters to load the bin/dat format\n",
    "num_channels = 64\n",
    "sampling_frequency = 20000\n",
    "gain_to_uV = 0.195\n",
    "offset_to_uV = 0\n",
    "dtype = \"int16\"\n",
    "time_axis = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si.read_binary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = si.read_binary(recording_file, num_chan=num_channels, sampling_frequency=sampling_frequency,\n",
    "                           dtype=dtype, gain_to_uV=gain_to_uV, offset_to_uV=offset_to_uV, \n",
    "                           time_axis=time_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `read_binary()` function returns a `RecordingExtractor` object. We can print it to visualize some of its properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further `annotate` the recording to tell SI that it is not filtered yet. This will prevent further mistakes in the pipieline, such as attempting to extract waveforms from unfiltered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording.annotate(is_filtered=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the `read_binary()` function is part of the `core` module (as it's used internally by SI to store data in a convenient format), the `extractor` module allows you to load many file formats used in electrophysiology. \n",
    "\n",
    "The extractors available in SI are all loaded using the [NEO](https://neo.readthedocs.io/en/stable/) python package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `RecordingExtractor` object extracts information about channel ids, channel locations (if present), the sampling frequency of the recording, and the extracellular traces (when prompted). The `BinaryRecordingExtractor` is designed specifically for raw binary files datasets (.bin, .dat, .raw).\n",
    "\n",
    "Here we load information from the recording using the built-in functions from the RecordingExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ids = recording.get_channel_ids()\n",
    "fs = recording.get_sampling_frequency()\n",
    "num_chan = recording.get_num_channels()\n",
    "num_segments = recording.get_num_segments()\n",
    "\n",
    "print(f'Channel ids: {channel_ids}')\n",
    "print(f'Sampling frequency: {fs}')\n",
    "print(f'Number of channels: {num_chan}')\n",
    "print(f\"Number of segments: {num_segments}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1a) Explore traces\n",
    "\n",
    "Explore the `recording.get_traces()` function. What are its arguments? What is the shape of the returned signals? What is the unit? \n",
    "\n",
    "Try to plot the traces of some channels using `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the traces here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: The `widgets` module includes several convenient plotting functions that can be used to explore the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w_ts = sw.plot_timeseries(recording, channel_ids=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on with the analysis, we have to load the probe information. For this we will use the [ProbeInterface](https://probeinterface.readthedocs.io/en/main/index.html) package. \n",
    "\n",
    "ProbeInterface allows to easily create, manipulate, and visualize neural probes. Moreover, it comes with a wide range of IO functions to import and export existing formats. Finally, we have created a public library of commercial probes (https://gin.g-node.org/spikeinterface/probeinterface_library/) that can be retrieved with a single line of code.\n",
    "\n",
    "Let's import `probeinterface`, download the probe and plot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import probeinterface as pi\n",
    "from probeinterface import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manufacturer = 'cambridgeneurotech'\n",
    "probe_name = 'ASSY-156-P-1'\n",
    "\n",
    "probe = pi.get_probe(manufacturer, probe_name)\n",
    "print(probe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most experiments, the neural probe has a connector, that is interfaced to an headstage, which in turn connects to the acquisition system. This *pathway* usually results in a channel remapping, which means that the order of the contacts on the probe is different than the order of the recorded traces.\n",
    "\n",
    "`probeinterface` provides a growing collection of common pathways that can be loaded directly to wire a device and apply the correct channel mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi.get_available_pathways()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe.wiring_to_device('ASSY-156>RHD2164')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_probe(probe, with_contact_id=True, with_device_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probe now has contact ids `id#` and device ids `dev#`! We can also visualize the probe information as a `pandas` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe.to_dataframe(complete=True).loc[:, [\"contact_ids\", \"shank_ids\", \"device_channel_indices\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that also the `shank_id` is loaded with the probe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_prb = recording.set_probe(probe, group_mode=\"by_shank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When loading the probe, the device indices (and all the other contact properties) are automatically sorted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_rec = recording_prb.get_probe()\n",
    "probe_rec.to_dataframe(complete=True).loc[:, [\"contact_ids\", \"shank_ids\", \"device_channel_indices\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Channels after loading the probe file: {recording_prb.get_channel_ids()}')\n",
    "print(f'Channel groups after loading the probe file: {recording_prb.get_channel_groups()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties \n",
    "\n",
    "`RecordingExtractor` object can have *properties*. A property is a piece of information attached to a channel, e.g. group or location.\n",
    "\n",
    "Similarly, for `SortingExtractor` objects (that we'll cover later), anything related to a unit can be stored as a property. \n",
    "\n",
    "We can check which properties are in the extractor as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Properties before loading the probe:\", list(recording.get_property_keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Properties after loading the probe:\", list(recording_prb.get_property_keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the probe we now have some new properties: `contact_vector`, `location`, and `group`.\n",
    "\n",
    "Let's add some new properties! \n",
    "The first 32 channels are in the CA1 area, the second 32 are in the CA3 area:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1b) Add a custom property\n",
    "\n",
    "We can use the `recording.set_property()` function to add custom properties to a SpikeInterface object. Properties are useful to store pieces of information across the analysis. \n",
    "\n",
    "Try to add a custom property to your `recording_prb` object (e.g. brain area, impedance, etc.). Check that the property was correctly added once you're done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_prb.set_property?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your property(ies) here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 1c) Can you add a property to a subset of channels? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Properties after adding custom properties:\", list(recording_prb.get_property_keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing <a class=\"anchor\" id=\"preprocessing\"></a>\n",
    "\n",
    "\n",
    "Now that the probe information is loaded we can do some preprocessing using `toolkit` module.\n",
    "\n",
    "We can filter the recordings, rereference the signals to remove noise, discard noisy channels, whiten the data, remove stimulation artifacts, etc. (more info [here](https://spiketoolkit.readthedocs.io/en/latest/preprocessing_example.html)).\n",
    "\n",
    "For this notebook, let's filter the recordings and apply common median reference (CMR). All preprocessing modules return new `RecordingExtractor` objects that apply the underlying preprocessing function. This allows users to access the preprocessed data in the same way as the raw data.\n",
    "\n",
    "We will focus only on the first shank (grouo `0`) for the following analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings_by_group = recording_prb.split_by(\"group\")\n",
    "print(recordings_by_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_to_sort = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_to_process = recordings_by_group[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we bandpass filter the recording:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "recording_f = st.bandpass_filter(recording_to_process, freq_min=300, freq_max=6000)\n",
    "\n",
    "w = sw.plot_timeseries(recording_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the after filtering we can observe spiking activity on many channels! We can also apply other preprocessing steps to further increase the quality of the recording. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2a) Explore noise reduction methods\n",
    "\n",
    "We can use the `toolkit` module to further increase the quality of the traces before spike sorting.\n",
    "Several available preprocessors are available for this purpose.\n",
    "\n",
    "- Explore the `toolkit` module (`st.`) to find functions that could remove noise (e.g. by re-referencing the signal).\n",
    "\n",
    "- Choose a preprocessing step and apply it to the filtered recording (`recording_f`)\n",
    "\n",
    "- Compare the traces to the filtered traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the toolkit module here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the right object to continue with the analysis\n",
    "recording_processed = recording_f "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2b) Visual exploration preprocessing methods with `ephyviewer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ephyviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = ephyviewer.mkQApp()\n",
    "win = ephyviewer.MainViewer(debug=True, show_auto_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_source = ephyviewer.SpikeInterfaceRecordingSource(recording=recording_to_process)\n",
    "sig_filtered_source = ephyviewer.SpikeInterfaceRecordingSource(recording=recording_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view1 = ephyviewer.TraceViewer(source=sig_source, name='signals')\n",
    "view1.params['scale_mode'] = 'same_for_all'\n",
    "win.add_view(view1)\n",
    "\n",
    "view2 = ephyviewer.TraceViewer(source=sig_filtered_source, name='signals filtered')\n",
    "view2.params['scale_mode'] = 'same_for_all'\n",
    "win.add_view(view2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can add more views here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win.show()\n",
    "app.exec_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are going to spike sort the data, let's first cut out a 5-minute recording, to speed up computations.\n",
    "\n",
    "We can easily do so with the `frame_slice()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = recording_processed.get_sampling_frequency()\n",
    "recording_sub = recording_processed.frame_slice(start_frame=0*fs, end_frame=300*fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Saving and loading SpikeInterface objects <a class=\"anchor\" id=\"save-load\"></a>\n",
    "\n",
    "All operations in SpikeInterface are *lazy*, meaning that they are not performed if not needed. This is why the creation of our filter recording was almost instantaneous. However, to speed up further processing, we might want to **save** it to a file and perform those operations (eg. filters, CMR, etc.) at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_saved = recording_sub.save(folder=\"preprocessed\", progress_bar=True, \n",
    "                                     n_jobs=4, total_memory=\"100M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `save` returns a new *cached* recording that has all the previously loaded information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Cached channels ids: {recording_saved.get_channel_ids()}')\n",
    "print(f'Channel groups after caching: {recording_saved.get_channel_groups()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After saving the SI object, we can easily load it back in a new session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_loaded = si.load_extractor(\"preprocessed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Loaded channels ids: {recording_loaded.get_channel_ids()}')\n",
    "print(f'Channel groups after loading: {recording_loaded.get_channel_groups()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can double check that the traces are exactly the same as the `recording_saved` that we saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2)\n",
    "w_saved = sw.plot_timeseries(recording_saved, ax=axs[0])\n",
    "w_loaded = sw.plot_timeseries(recording_loaded, ax=axs[1])\n",
    "axs[0].set_title(\"Saved\")\n",
    "axs[1].set_title(\"Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: the same saving mechanisms are available also for all SortingExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Spike sorting <a class=\"anchor\" id=\"spike-sorting\"></a>\n",
    "\n",
    "We can now run spike sorting on the above recording.\n",
    "\n",
    "Let's first check the installed sorters in SpikeInterface.\n",
    "We will sort the bandpass cached filtered recording the `recording_saved` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.installed_sorters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve the parameters associated to any sorter with the `get_default_params()` function from the `sorters` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorter_name = 'sorter-name-here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.get_default_params(sorter_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.get_params_description(sorter_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4a) Spike sort your data\n",
    "\n",
    "The `ss.run_sorter()` function from the `sorters` module is where the spike sorting happens! The function returns a `SortingExtractor` object, which allows you to retrieve spiking data (e.g. unit ids, spike trains, etc.)\n",
    "\n",
    "Run a spike sorter installed on your system and explore the returned `SortingExtractor` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.run_sorter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To modify a parameter, we can easily pass it to the `run` function as an extra argument!\n",
    "For example, let's set the `filter` parameter to False as the recording is already preprocessed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run spike sorting on entire recording\n",
    "sorting = ss.run_sorter(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorting)\n",
    "\n",
    "sorting.?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4b) Change a spike sorter parameter\n",
    "\n",
    "Parameters (listed above) can be directly passed as extra arguments to the `ss.run_sorter()` function.\n",
    "\n",
    "Try to choose a parameter, change its default value, and run spike sorting again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run spike sorting on entire recording\n",
    "sorting1 = ss.run_sorter(..., my_param1=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other spike sorting options \n",
    "\n",
    "You don't need to run these, but they might be helpful for reference in the future :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Install and run a MATLAB-based sorter (requires MATLAB)\n",
    "\n",
    "For MATLAB-based sorters, all you need to do is cloning the sorter repo and point it to SpikeInterface:\n",
    "\n",
    "Let's clone [`ironclust`](https://github.com/flatironinstitute/ironclust) in the current directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/flatironinstitute/ironclust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all we have to tell the IronClustSorter class where is the ironclust repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.IronClustSorter.set_ironclust_path('./ironclust')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can also set a global environment variable called `IRONCLUST_PATH`. In that case we don't need to set the path in each session because the sorter class looks for this environment variable.\n",
    "\n",
    "Now ironclust should be installed and we can run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.IronClustSorter.ironclust_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.installed_sorters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run spike sorting by group\n",
    "sorting_IC = ss.run_sorter(\"ironclust\", recording_saved, \n",
    "                           output_folder='results_IC',\n",
    "                           verbose=True)\n",
    "print(f'IronClust found {len(sorting_IC.get_unit_ids())} units')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spike sorting returns a `SortingExtractor` object. Let's see some of its functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Ironclust unit ids: {sorting_IC.get_unit_ids()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Spike train of a unit: {sorting_IC.get_unit_spike_train(13)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `spikewidgets` functions for some quick visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_rs = sw.plot_rasters(sorting_IC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Running multiple sorter jobs in parallel\n",
    "\n",
    "So far we have seen how to run one sorter at a time. SI provides a convenient launcher in order to run multiple sorters on multiple recordings with one line of code!\n",
    "\n",
    "The `run_sorters()` function of the `sorter` module allows you to specify a list of sorters to use on a list (or dictionary) of parameters. The jobs are by default ran in a loop, but the `engine` argument enables to specify a parallel backend (`joblib` or `dask`) and relative parameters.\n",
    "\n",
    "In the following example, we run the 2 jobs to run `herdingspikes` and `ironclust` in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorting_outputs = ss.run_sorters(sorter_list=[\"herdingspikes\", \"ironclust\"],\n",
    "                                 recording_dict_or_list={\"group0\": recording_saved},\n",
    "                                 working_folder=\"all_sorters\",\n",
    "                                 verbose=False,\n",
    "                                 engine=\"joblib\",\n",
    "                                 engine_kwargs={'n_jobs': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned `sorting_outputs` variable is a dictionary that has (rec_name, sorter_name) as keys, and the `SortingExtractor` objects as valus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorting_outputs.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of the tutorial, let's pick the `ironclust` output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_IC = sorting_outputs[('group0', 'ironclust')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Spike sort in Docker containers\n",
    "###  (Linux and MacOS only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some sorters are hard to install! To alleviate this headache, SI provides a built-in mechanism to run a spike sorting job in a docker container.\n",
    "\n",
    "We are maintaining a set of sorter-specific docker files in the [spikeinterface-dockerfiles repo](<https://github.com/SpikeInterface/spikeinterface-dockerfiles>)\n",
    "and most of the docker images are available on Docker Hub from the [SpikeInterface organization](<https://hub.docker.com/orgs/spikeinterface/repositories>).\n",
    "\n",
    "Running spike sorting in a docker container just requires to:\n",
    "\n",
    "1. have docker installed\n",
    "2. have docker python SDK installed (`pip install docker`)\n",
    "\n",
    "When docker is installed, you can simply run the sorter in a specified docker image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ss.installed_sorters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_SC = ss.run_spykingcircus(recording_saved, output_folder=\"results_SC\",\n",
    "                                  docker_image=\"spikeinterface/spyking-circus-base:1.0.7\", \n",
    "                                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_rasters(sorting_SC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Extracting waveforms <a class=\"anchor\" id=\"waveforms\"></a>\n",
    "\n",
    "The core of postprocessing spike sorting results revolves around extracting waveforms from paired recording-sorting objects.\n",
    "\n",
    "The `WaveformExtractor` object has convenient functions to retrieve waveforms and templates.\n",
    "Let's see how it works.\n",
    "\n",
    "To extract the waveforms, we can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si.extract_waveforms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we = si.extract_waveforms(recording_saved, sorting, folder=\"waveforms_si\", progress_bar=True,\n",
    "                          n_jobs=1, total_memory=\"500M\", overwrite=True)\n",
    "print(we)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all waveforms are computed and stored in the provided `waveforms_si` folder. We can now retrieve waveforms and templates easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5a) Explore waveforms and templates\n",
    "\n",
    "The `WaveformExtractor` object (`we`) has convenient functions to retrieve waveforms and templates (average waveforms).\n",
    "\n",
    "- Retrieve some waveforms and templates and inspect them\n",
    "- Are waveform extracted from all spikes? If not, can you explore the function docs and find a way to compute waveforms for all spikes?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore waveforms and templates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5b) Find `widgets` for plotting waveforms\n",
    "\n",
    "Use the `widgets` module to visualize waveform extractor objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore widgets here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Postprocessing <a class=\"anchor\" id=\"postprocessing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postprocessing spike sorting results ranges from computing additional information, such as spike amplitudes and Principal Component Analisys (PCA) scores, to computing features of the extracellular waveforms, similarity between templates and crosscorrelograms. All of this is possible with the `toolkit` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA scores\n",
    "\n",
    "PCA scores can be easily computed with the `compute_principal_components()` function. Similarly to the `extract_waveforms`, the function returns an object of type `WaveformPrincipalComponent` that allows to retrieve all pc scores on demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = st.compute_principal_components(we, n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc0 = pc.get_components(unit_id=0)\n",
    "all_labels, all_pcs = pc.get_all_components()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For pc scores of a single unit, the dimension is (num_spikes, num_components, num_channels). \n",
    "The `get_all_components()` function returns an array with the label/unit id for each component (`all_labels`) and an array of dimension (num_all_samples, num_components, num_channels). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: The `get_components()` and `get_all_components()` will be renamed `get_projections()` and `get_all_projections()` in the next release."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spike amplitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spike amplitudes can be computed with the `get_spike_amplitudes` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes = st.get_spike_amplitudes(we, outputs=\"concatenated\", progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, all amplitudes are concatenated in one array.\n",
    "\n",
    "The correspinding spike times and labels can be easily retrieved as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spike_times, all_spike_labels = sorting.get_all_spike_trains()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [0] index is to select the first segment. In case of multiple segments each element will correspond to a different segment and will contain spike times and labels for that segment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6a) Plot pca projections and amplitudes over time\n",
    "\n",
    "Explore the principal component space and amplitudes using `matplotlib`\n",
    "\n",
    "- Plot projections of two units on multiple channels and pc components\n",
    "- Plot the spike amplitudes of a unit over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore pc and amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute template metrics\n",
    "\n",
    "Template metrics, or extracellular features, such as peak to valley duration or full-width half maximum, are important to classify neurons into putative classes (excitatory - inhibitory). The `toolkit` allows one to compute several of these metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(st.get_template_metric_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_metrics = st.calculate_template_metrics(we)\n",
    "display(template_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about these template metrics, we refer to this [documentation](https://github.com/AllenInstitute/ecephys_spike_sorting/tree/master/ecephys_spike_sorting/modules/mean_waveforms) from the Allen Institute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Viewers <a class=\"anchor\" id=\"viewers\"></a>\n",
    "\n",
    "The `spikeinterface-gui` allows you to interactively explore a spike sorting output once waveforms are extracted.\n",
    "\n",
    "\n",
    "### Exercise 7a) Use the `spikeinterface-gui` to epxlore the sorting output\n",
    "\n",
    "Launch the `sigui` on the waveforms folder and explore all different views.\n",
    "\n",
    "- Can you find some bad units?\n",
    "- Are there missed spikes or spike sorting errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sigui waveforms_si"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Validation and curation <a class=\"anchor\" id=\"curation\"></a>\n",
    "\n",
    "The `toolkit` module also provides several functions to compute qualitity metrics to validate the spike sorting results.\n",
    "\n",
    "Let's see what metrics are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(st.get_quality_metric_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc = st.compute_quality_metrics(we_all, waveform_principal_component=pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(qc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about these waveform features, we refer to this [documentation](https://allensdk.readthedocs.io/en/latest/_static/examples/nb/ecephys_quality_metrics.html) from the Allen Institute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic curation based on quality metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A viable option to curate (or at least pre-curate) a spike sorting output is to filter units based on quality metrics. As we have already computed quality metrics a few lines above, we can simply filter the `qc` dataframe based on some thresholds.\n",
    "\n",
    "Here, we'll only keep units with an SNR > 5 and an ISI violation threshold < 0.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_thresh = 5\n",
    "isi_viol_thresh = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A straightforward way to filter a pandas dataframe is via the `query`.\n",
    "We first define our query (make sure the names match the column names of the dataframe):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_query = f\"snr > {snr_thresh} & isi_violations_rate < {isi_viol_thresh}\"\n",
    "print(our_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then we can use the query to select units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_units = qc.query(our_query)\n",
    "keep_unit_ids = keep_units.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_auto = sorting.select_units(keep_unit_ids)\n",
    "print(f\"Number of units before curation: {len(sorting.get_unit_ids())}\")\n",
    "print(f\"Number of units after curation: {len(sorting_auto.get_unit_ids())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8a) Extract waveforms on the curated sorting and explore the output in the spikeinterface-gui\n",
    "\n",
    "Re-extract waveforms using the curated output and explore the results.\n",
    "\n",
    "Is the spike sorting quality improved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# choose a different folder!\n",
    "we_curated = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sigui new_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8b) Explore different curation strategies in the spikeinterface-gui\n",
    "\n",
    "- Try to use different thresholds and/or quality metrics to automatically curate the spike sorting output.\n",
    "- View the result in the `spikeinterface-gui`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try different metrics/thresholds for curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Exporters <a class=\"anchor\" id=\"exporters\"></a>\n",
    "\n",
    "The `exporters` module provides functions to export the spike sorting results to different frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Phy for manual curation\n",
    "\n",
    "To perform manual curation we can export the data to [Phy](https://github.com/cortex-lab/phy). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.exporters import export_to_phy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_to_phy(we_curated, output_folder='phy',\n",
    "              progress_bar=True, total_memory='100M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!phy template-gui phy/params.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After curating the results we can reload it using the `PhySortingExtractor` and exclude the units that we labeled as `noise`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorting_phy_curated = se.PhySortingExtractor('phy/', exclude_cluster_groups=['noise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of units before curation: {len(sorting.get_unit_ids())}\")\n",
    "print(f\"Number of units after curation: {len(sorting_phy_curated.get_unit_ids())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export spike sorting report\n",
    "\n",
    "The SpikeInterface report automatically saves summary and unit-specific views to save and inspect your spike sorting output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.exporters import export_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "export_report(waveform_extractor=we_all, output_folder=\"SI_report\", format=\"pdf\", \n",
    "              metrics=qc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
